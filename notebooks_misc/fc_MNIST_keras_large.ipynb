{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "import keras\n",
    "import sys\n",
    "print (\"Keras {} TF {} Python {}\".format(keras.__version__, tf.__version__, sys.version_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Somewho not working from docker container\n",
    "if False:\n",
    "    from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "    # Loads (if necessary) and caches the MNIST training data\n",
    "    # Used one_hot encoding, and reshaping --> 784\n",
    "    mnist = read_data_sets(\"../data/\", one_hot=True, reshape=True, validation_size=2000)\n",
    "    X_train = mnist.train.images\n",
    "    X_val = mnist.validation.images\n",
    "\n",
    "    Y_train = mnist.train.labels\n",
    "    Y_val = mnist.validation.labels\n",
    "\n",
    "    X_train.shape, Y_train.shape, Y_val.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the training \n",
    "\n",
    "Below are the tensorboard files for training MNIST on the whole data set. The training has been performed on a cluster of TitanX GPUs using the script [fc_MNIST_keras_large.py](https://github.com/oduerr/dl_tutorial/blob/master/tensorflow/path_to_fc_nets/fc_MNIST_keras_large.py)\n",
    "\n",
    "We first download the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12M\r\n",
      "-rw-r--r-- 1 root root 6.0K Feb 28 17:51 Explanation_of_loss.ipynb\r\n",
      "drwxrwxr-x 3 root root  102 Mar  6 13:50 \u001b[0m\u001b[01;34m__MACOSX\u001b[0m/\r\n",
      "-rw-r--r-- 1 root root 4.9M Mar  6 14:31 batch_dropout.keras\r\n",
      "-rw-r--r-- 1 root root  26K Mar  6 14:36 fc_MNIST_keras_large.ipynb\r\n",
      "-rw-r--r-- 1 root root 4.3K Feb 20 09:48 figure_feeding_fetching.ipynb\r\n",
      "drwxr-xr-x 9 root root  306 Mar  6 11:51 \u001b[01;34mtb_full_mnist\u001b[0m/\r\n",
      "-rw-r--r-- 1 root root 6.6M Mar  6 14:24 \u001b[01;31mtb_full_mnist.zip\u001b[0m\r\n",
      "drwxr-xr-x 5 root root  170 Mar  6 13:48 \u001b[01;34mtensorboard\u001b[0m/\r\n",
      "-rw-r--r-- 1 root root  20K Mar  6 14:04 weight_initialization.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import os\n",
    "if not os.path.isfile('tb_full_mnist.zip'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/bcbqpptvdlbgdch/tb_full_mnist.zip?dl=1\",\n",
    "    \"tb_full_mnist.zip\")\n",
    "    !unzip tb_full_mnist.zip\n",
    "%ls -hl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir=tb_full_mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model\n",
    "Loading the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 4.9M Mar  6 14:31 batch_dropout.keras\r\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import os\n",
    "if not os.path.isfile('batch_dropout.keras'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/spy3hzti8tiic42/batch_dropout.keras?dl=1\",\n",
    "    \"batch_dropout.keras\")\n",
    "%ls -hl batch_dropout.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 500)           392500      dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 500)           2000        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 500)           0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 500)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            25050       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 50)            200         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 50)            0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 50)            0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         activation_2[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 420,260\n",
      "Trainable params: 419,160\n",
      "Non-trainable params: 1,100\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('batch_dropout.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
