{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Simple RNN TF1\n",
    "\n",
    "** This is the implementation for TensorFlow 1.0 and python 3.4. It uses the Keras or the TF-RNN library for training.** For another more manual implementation see simple_rnn in dl_tutorial\n",
    "\n",
    "In this notebook we consider a simple example of an RNN and used a quite artifical data generating process (if you have a better idea / story please contact me). \n",
    "\n",
    "The example has been motivated by:\n",
    "http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html. \n",
    "\n",
    "Other Resources for RNNs:\n",
    "\n",
    "* http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n",
    "* http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html\n",
    "* http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "* http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* http://www.deeplearningbook.org/contents/rnn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1.0.0',\n",
       " sys.version_info(major=3, minor=4, micro=3, releaselevel='final', serial=0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from six.moves.cPickle import loads\n",
    "import numpy as np\n",
    "import sys\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "import keras\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__, sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Global config variables (see below)\n",
    "num_steps = 40     # number of truncated backprop steps\n",
    "batch_size = 200  # number of minibatches b\n",
    "num_classes_in = 3   # number of classes in the input\n",
    "num_classes_out = 2   # number of classes in the output\n",
    "state_size = 4    # number of classes in the state\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Helper functions\n",
    "def one_hot(Y, max):\n",
    "    d = np.zeros((len(Y),max), dtype='int32')\n",
    "    for row,col in enumerate(Y):\n",
    "        d[row, col] = 1\n",
    "    return d    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Definition of the task\n",
    "\n",
    "We consider a network which predicts at each point in time a variable $\\hat{y}_t$ based on earlier values of $\\hat{y}_{t'}$ covariates $x_t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Example data  (I screama, you screama, we all screama for I screama)\n",
    "\n",
    "We need some data to play around with RNNs. They are capable of doing quite complicated things such as language models and so on. For this example, we want to generate the data ourself. We have to come up with a process which creates $x_t$ which itself can be influcenced by events $x_{t'}$ which happend before $t$. Further, we have to come up with $y_t$ which depends on $x_t'$ for timepoints $t' \\le t$. \n",
    "\n",
    "To keep it simple, we analyse the following quite artifical process in which the weather $x_{t'}$ for $t' \\le t$ influences our stock on icecream $y_t$. We then see if the RNN is capable of reconstructing that process.\n",
    "\n",
    "#### Definition of the simple process\n",
    "The weather $x_t$ at a certain point in time $t$ has three states (sunny, rainy, cloudy), which we model as $x_t = (1,0,0)$, $x_t = (0,1,0)$, and $x_t = (0,0,1)$ repectively. We assume that the weather is completly random (of course we could model more complex scenarios). \n",
    "\n",
    "We have an icecream store capable of holding 2 units of icecream and we start with a full store. When it is sunny we sell one unit of icecream. We have the strange policy that we order  on unit of icecream when it's cloudy. It takes 3 days to deliever the ice cream, we accept the ice cream if we do not have a full stock.\n",
    "\n",
    "This enables us to model $y_t$ the state of the store $(1,0)$ for out of stock and $(0,1)$ for in stock. We create the one-hot-encoded data in the graph later. For now we use integers but keep in mind that the data is categorical. \n",
    "\n",
    "** The important part is that, we have values $y_t$ which can be prediced from earlier** $x_t$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    Xs = np.array(np.random.choice(3, size=(size,))) #Random Weather\n",
    "    Y = []\n",
    "    ice = 2 #Our stock of icecream at start\n",
    "    for t,x in enumerate(Xs):\n",
    "        # (t-3) >= 0 the first ice cream could be delivered on day 3\n",
    "        # Xs[t - 3] claudy three days before today => we ordered ice cream\n",
    "        # ice < 2 not full\n",
    "        if (t - 3) >= 0 and Xs[t - 3] == 1 and ice < 2: \n",
    "            ice += 1\n",
    "        if x == 0: # It is sunny we therefore sell ice, if we have\n",
    "            if ice > 0: # We have ice cream\n",
    "                ice -= 1\n",
    "        if ice > 0: #We are not out of stock\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "    return Xs, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2,\n",
       "        1, 0, 1, 1]),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = gen_data(50000) #Global variables holding the input and output\n",
    "(X_train[0:50], Y_train[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Forward pass in numpy\n",
    "To better illustrate the used method, we first do a forward-pass of the RNN using numpy. We load the weights which we calculated previously with the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_, b_, V_, bv_ = np.load('14_rnn_weights_tf1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Architecture of the network \n",
    "We now define the network, we do not consider the output nodes yet.\n",
    "A single RNN cell is shown in the figure below in the middle:\n",
    "\n",
    "![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n",
    "Image taken from: [Colah's RNN Blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "The joining of the two lines coming from the previous state $h_{t-1}$ and the current x-values $x_t$ is a concantination to a vector  $[h_{t-1}, x_{t}]$ of size `state_size + num_classes_in`. Alternatively, instead of concatinating, one could also use two matrices $W_x$ and $W_h$ and keep the states seperate. This is mathematically completely identical. The new state $h_t$ is then calculated as:\n",
    "\n",
    "$$\n",
    "    h_{t} = \\tanh([h_{t-1}, x_{t}] \\cdot W + b) = \\tanh(h_{t-1} \\cdot W_h + x_{t} \\cdot U + b)\n",
    "$$\n",
    "\n",
    "The dynamic of the hidden state $h_{t}$ is determined by $W$ (and $b$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.19089293,  1.2079829 ,  0.00908419, -0.91102362],\n",
       "        [-1.07885635, -0.34288317,  0.72712117,  1.41788387],\n",
       "        [-0.20597383, -0.19254826,  0.7025221 , -0.54543966],\n",
       "        [ 1.03414631,  0.67596245, -0.93610775,  0.37894768],\n",
       "        [-0.16711316,  1.02640092, -0.89726377, -0.42267284],\n",
       "        [ 0.20204762, -1.21461511,  0.02345279,  0.41776735],\n",
       "        [-1.44821215,  0.28976035, -1.87600672, -1.1563133 ]], dtype=float32),\n",
       " array([ 0.1347418 ,  0.28151226,  0.17300364, -0.32107899], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_, b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.] ---> [-0.0711118   0.08873004  0.70417075 -0.69960102]\n"
     ]
    }
   ],
   "source": [
    "# The first state\n",
    "h0 = np.zeros(state_size) #We start with 0 initial state\n",
    "x1 = one_hot(X_train, num_classes_in)[0] #Make a vector\n",
    "\n",
    "#<---- your code here (calculate the hidden state h1) ---->\n",
    "h1 = np.tanh(np.matmul(np.concatenate([x1, h0]), W_) + b_)\n",
    "#<---- end your code here ---->\n",
    "\n",
    "print(h0, \"--->\", h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We could repeat those transitions of the hidden states to get a sequence of hidden states:\n",
    "\n",
    "$h_0 \\rightarrow h_1 \\rightarrow h_2 \\rightarrow h_3 \\rightarrow h_4 \\ldots $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rnn_forward(state, X_train):\n",
    "    hs = []\n",
    "    for t in range(len(X_train)):\n",
    "        # Note that TF concatenates [Input, State]\n",
    "        state = np.tanh(np.matmul(np.concatenate([X_train[t,:],state]), W_) + b_)\n",
    "        hs.append(state)\n",
    "    return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.0711118 ,  0.08873004,  0.70417075, -0.69960102]),\n",
       " array([ 0.76614542,  0.4418166 ,  0.90478852, -0.19104017]),\n",
       " array([ 0.80289923, -0.09371934,  0.14058029, -0.16258438]),\n",
       " array([ 0.77733682,  0.30737024,  0.47485703, -0.26912559]),\n",
       " array([ 0.82809942,  0.93229872, -0.29620752, -0.50640012])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_forward(h0, one_hot(X_train[0:5],num_classes_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We add some output. For each time step the output is produced by multiplying the hidden state with:\n",
    "\n",
    "$o_t = h_t \\cdot V + b_{\\tt{v}}$\n",
    "\n",
    "This is a logit, the final the probability of output class is the softmax of the logit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.24407249,  0.67026118]), array([ 0.28611385,  0.71388615]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<---- your code here (calculate the output state o1 for timestep 1 from h1, V_ and the bias bv_) ---->\n",
    "o1 = np.matmul(h1, V_) + bv_\n",
    "#<---- your code here (calculate probability from the state o1) using softmax ---->\n",
    "prob_1 = np.exp(o1)/np.sum(np.exp(o1))\n",
    "#<---- end your code here  ---->\n",
    "o1, prob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h = rnn_forward(h0, one_hot(X_train,3))\n",
    "pt = []\n",
    "for t in range(len(h)):\n",
    "    ot = np.matmul(h[t], V_) + bv_\n",
    "    pt.append(np.exp(ot)/np.sum(np.exp(ot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 0.28611385,  0.71388615]),\n",
       "  array([ 0.72571267,  0.27428733]),\n",
       "  array([ 0.16161706,  0.83838294]),\n",
       "  array([ 0.58954736,  0.41045264]),\n",
       "  array([ 0.98113328,  0.01886672]),\n",
       "  array([ 0.98589376,  0.01410624]),\n",
       "  array([ 0.9805026,  0.0194974]),\n",
       "  array([ 0.97813046,  0.02186954]),\n",
       "  array([ 0.98805885,  0.01194115]),\n",
       "  array([ 0.96179709,  0.03820291])],\n",
       " array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0]),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt[0:10], np.argmax(pt[0:30],axis=1), Y_train[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98318000000000005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.argmax(pt, axis=1) == Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tot_loss = 0\n",
    "for i in range(len(Y_train)):\n",
    "    tot_loss += -np.log(pt[i][Y_train[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.069289919833816341"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_loss / len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training of the network\n",
    "### Preparation of the Minibatch\n",
    "\n",
    "In this example, we have in principle a large stream of data $x$ and $y$. For efficiency reason we split the stream in minibatches of a certain length. For this task we could also imagin to have several realizations of that icecream process, so that it would also be natural to split the process into mini batches. \n",
    "\n",
    "For simplicity, we create the minibatch by randomly cutting out `batch_size` entries of fixed length `num_steps`. Other, more advanced ways of doing so are possible. See e.g. https://danijar.com/variable-sequence-lengths-in-tensorflow/. For the time being, we thus consider the input tensor $X_{btc}$ for the minibatch to be of the following form:\n",
    "\n",
    "* $b$ having `batch_size` entries\n",
    "* $t$ loops over the unrolled timestamps (`num_steps`)\n",
    "* $c$ has the dimension of the one-hot-coded input classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_matrix(Xs, Ys, size = 32, num_steps = 50):\n",
    "    data_x = np.zeros([size, num_steps, 3], dtype=np.int32)\n",
    "    data_y = np.zeros([size, num_steps, 2], dtype=np.int32)\n",
    "    for i in range(1,size):\n",
    "        s = int(np.random.uniform(0, len(Xs) - num_steps))\n",
    "        data_x[i] = one_hot(Xs[s : s + num_steps],3)\n",
    "        data_y[i] = one_hot(Ys[s : s + num_steps],2)\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 40, 3), (10000, 40, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = data_matrix(X_train, Y_train, size=10000, num_steps=num_steps)\n",
    "X.shape, Y.shape\n",
    "#print (X[0:2,0:5])\n",
    "#print (Y[0:2,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the model with keras\n",
    "\n",
    "**Keras assumes (batch, time, input_dimension)** as input tensor. The batch dimension needs not to be specified (side note that specifying it to `None` would not work).\n",
    "\n",
    "\n",
    "In our model we calculate the loss using all hidden timepoints. This is many-to-many situation is different for example to a sentiment classifier, where we we have a many-to-one situation. \n",
    "\n",
    "Not just the latest one (in time). Hence we set `return_sequences=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "rnn = keras.layers.SimpleRNN(state_size, input_shape=(num_steps, 3), return_sequences=True, name='RNN')\n",
    "model.add(rnn) \n",
    "#model.input_shape --> (None, 40, 3)\n",
    "#model.output_shape --> (None, 40, 4) \n",
    "\n",
    "# Add an output layer connecting with the hidden state of the RNN (use the TimeDistributed Layer)\n",
    "#model.add(keras.layers.Dense(2))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(2)))\n",
    "#model.output_shape --> (None, 40, 2) \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "1s - loss: 4.4047 - acc: 0.4217 - val_loss: 3.5944 - val_acc: 0.4785\n",
      "Epoch 2/100\n",
      "1s - loss: 1.7687 - acc: 0.5050 - val_loss: 0.7142 - val_acc: 0.5480\n",
      "Epoch 3/100\n",
      "2s - loss: 0.6518 - acc: 0.6208 - val_loss: 0.6134 - val_acc: 0.6677\n",
      "Epoch 4/100\n",
      "1s - loss: 0.5766 - acc: 0.6979 - val_loss: 0.5170 - val_acc: 0.7385\n",
      "Epoch 5/100\n",
      "1s - loss: 0.4276 - acc: 0.8050 - val_loss: 0.3853 - val_acc: 0.8395\n",
      "Epoch 6/100\n",
      "1s - loss: 0.3442 - acc: 0.8502 - val_loss: 0.3316 - val_acc: 0.8546\n",
      "Epoch 7/100\n",
      "1s - loss: 0.3057 - acc: 0.8517 - val_loss: 0.3001 - val_acc: 0.8426\n",
      "Epoch 8/100\n",
      "1s - loss: 0.2781 - acc: 0.8245 - val_loss: 0.2769 - val_acc: 0.7880\n",
      "Epoch 9/100\n",
      "1s - loss: 0.2574 - acc: 0.7667 - val_loss: 0.2643 - val_acc: 0.7455\n",
      "Epoch 10/100\n",
      "1s - loss: 0.2496 - acc: 0.7239 - val_loss: 0.2608 - val_acc: 0.7048\n",
      "Epoch 11/100\n",
      "1s - loss: 0.2472 - acc: 0.6963 - val_loss: 0.2561 - val_acc: 0.6979\n",
      "Epoch 12/100\n",
      "1s - loss: 0.2454 - acc: 0.6860 - val_loss: 0.2543 - val_acc: 0.6940\n",
      "Epoch 13/100\n",
      "1s - loss: 0.2427 - acc: 0.6789 - val_loss: 0.2509 - val_acc: 0.6722\n",
      "Epoch 14/100\n",
      "1s - loss: 0.2409 - acc: 0.6722 - val_loss: 0.2476 - val_acc: 0.6721\n",
      "Epoch 15/100\n",
      "1s - loss: 0.2388 - acc: 0.6679 - val_loss: 0.2504 - val_acc: 0.6740\n",
      "Epoch 16/100\n",
      "1s - loss: 0.2371 - acc: 0.6683 - val_loss: 0.2458 - val_acc: 0.6600\n",
      "Epoch 17/100\n",
      "1s - loss: 0.2362 - acc: 0.6667 - val_loss: 0.2446 - val_acc: 0.6648\n",
      "Epoch 18/100\n",
      "1s - loss: 0.2348 - acc: 0.6681 - val_loss: 0.2453 - val_acc: 0.6731\n",
      "Epoch 19/100\n",
      "1s - loss: 0.2325 - acc: 0.6737 - val_loss: 0.2412 - val_acc: 0.6767\n",
      "Epoch 20/100\n",
      "3s - loss: 0.2314 - acc: 0.6780 - val_loss: 0.2426 - val_acc: 0.6731\n",
      "Epoch 21/100\n",
      "1s - loss: 0.2305 - acc: 0.6824 - val_loss: 0.2380 - val_acc: 0.6899\n",
      "Epoch 22/100\n",
      "1s - loss: 0.2293 - acc: 0.6833 - val_loss: 0.2378 - val_acc: 0.6907\n",
      "Epoch 23/100\n",
      "1s - loss: 0.2290 - acc: 0.6874 - val_loss: 0.2372 - val_acc: 0.6922\n",
      "Epoch 24/100\n",
      "1s - loss: 0.2276 - acc: 0.6912 - val_loss: 0.2384 - val_acc: 0.6827\n",
      "Epoch 25/100\n",
      "1s - loss: 0.2285 - acc: 0.6850 - val_loss: 0.2368 - val_acc: 0.6728\n",
      "Epoch 26/100\n",
      "2s - loss: 0.2275 - acc: 0.6887 - val_loss: 0.2370 - val_acc: 0.6908\n",
      "Epoch 27/100\n",
      "2s - loss: 0.2264 - acc: 0.6874 - val_loss: 0.2377 - val_acc: 0.6642\n",
      "Epoch 28/100\n",
      "1s - loss: 0.2249 - acc: 0.6826 - val_loss: 0.2329 - val_acc: 0.6796\n",
      "Epoch 29/100\n",
      "1s - loss: 0.2244 - acc: 0.6797 - val_loss: 0.2341 - val_acc: 0.6732\n",
      "Epoch 30/100\n",
      "1s - loss: 0.2228 - acc: 0.6771 - val_loss: 0.2319 - val_acc: 0.6763\n",
      "Epoch 31/100\n",
      "1s - loss: 0.2231 - acc: 0.6762 - val_loss: 0.2315 - val_acc: 0.6702\n",
      "Epoch 32/100\n",
      "1s - loss: 0.2224 - acc: 0.6723 - val_loss: 0.2325 - val_acc: 0.6796\n",
      "Epoch 33/100\n",
      "2s - loss: 0.2218 - acc: 0.6689 - val_loss: 0.2303 - val_acc: 0.6569\n",
      "Epoch 34/100\n",
      "2s - loss: 0.2207 - acc: 0.6678 - val_loss: 0.2321 - val_acc: 0.6606\n",
      "Epoch 35/100\n",
      "1s - loss: 0.2186 - acc: 0.6659 - val_loss: 0.2297 - val_acc: 0.6619\n",
      "Epoch 36/100\n",
      "1s - loss: 0.2178 - acc: 0.6655 - val_loss: 0.2333 - val_acc: 0.6378\n",
      "Epoch 37/100\n",
      "1s - loss: 0.2167 - acc: 0.6618 - val_loss: 0.2289 - val_acc: 0.6671\n",
      "Epoch 38/100\n",
      "1s - loss: 0.2165 - acc: 0.6625 - val_loss: 0.2308 - val_acc: 0.6479\n",
      "Epoch 39/100\n",
      "1s - loss: 0.2158 - acc: 0.6591 - val_loss: 0.2286 - val_acc: 0.6619\n",
      "Epoch 40/100\n",
      "1s - loss: 0.2148 - acc: 0.6592 - val_loss: 0.2283 - val_acc: 0.6564\n",
      "Epoch 41/100\n",
      "1s - loss: 0.2136 - acc: 0.6591 - val_loss: 0.2280 - val_acc: 0.6453\n",
      "Epoch 42/100\n",
      "1s - loss: 0.2142 - acc: 0.6551 - val_loss: 0.2257 - val_acc: 0.6600\n",
      "Epoch 43/100\n",
      "1s - loss: 0.2132 - acc: 0.6551 - val_loss: 0.2279 - val_acc: 0.6683\n",
      "Epoch 44/100\n",
      "1s - loss: 0.2124 - acc: 0.6569 - val_loss: 0.2252 - val_acc: 0.6535\n",
      "Epoch 45/100\n",
      "1s - loss: 0.2121 - acc: 0.6555 - val_loss: 0.2259 - val_acc: 0.6663\n",
      "Epoch 46/100\n",
      "1s - loss: 0.2106 - acc: 0.6585 - val_loss: 0.2257 - val_acc: 0.6540\n",
      "Epoch 47/100\n",
      "2s - loss: 0.2109 - acc: 0.6556 - val_loss: 0.2260 - val_acc: 0.6485\n",
      "Epoch 48/100\n",
      "2s - loss: 0.2099 - acc: 0.6562 - val_loss: 0.2249 - val_acc: 0.6505\n",
      "Epoch 49/100\n",
      "1s - loss: 0.2095 - acc: 0.6581 - val_loss: 0.2231 - val_acc: 0.6554\n",
      "Epoch 50/100\n",
      "1s - loss: 0.2091 - acc: 0.6555 - val_loss: 0.2231 - val_acc: 0.6511\n",
      "Epoch 51/100\n",
      "1s - loss: 0.2080 - acc: 0.6527 - val_loss: 0.2238 - val_acc: 0.6480\n",
      "Epoch 52/100\n",
      "1s - loss: 0.2080 - acc: 0.6525 - val_loss: 0.2427 - val_acc: 0.5972\n",
      "Epoch 53/100\n",
      "1s - loss: 0.2081 - acc: 0.6490 - val_loss: 0.2236 - val_acc: 0.6477\n",
      "Epoch 54/100\n",
      "1s - loss: 0.2077 - acc: 0.6507 - val_loss: 0.2250 - val_acc: 0.6372\n",
      "Epoch 55/100\n",
      "1s - loss: 0.2078 - acc: 0.6482 - val_loss: 0.2259 - val_acc: 0.6320\n",
      "Epoch 56/100\n",
      "1s - loss: 0.2069 - acc: 0.6553 - val_loss: 0.2231 - val_acc: 0.6483\n",
      "Epoch 57/100\n",
      "1s - loss: 0.2083 - acc: 0.6442 - val_loss: 0.2296 - val_acc: 0.6267\n",
      "Epoch 58/100\n",
      "1s - loss: 0.2066 - acc: 0.6486 - val_loss: 0.2228 - val_acc: 0.6517\n",
      "Epoch 59/100\n",
      "1s - loss: 0.2067 - acc: 0.6490 - val_loss: 0.2227 - val_acc: 0.6405\n",
      "Epoch 60/100\n",
      "1s - loss: 0.2065 - acc: 0.6483 - val_loss: 0.2266 - val_acc: 0.6213\n",
      "Epoch 61/100\n",
      "1s - loss: 0.2066 - acc: 0.6458 - val_loss: 0.2263 - val_acc: 0.6600\n",
      "Epoch 62/100\n",
      "1s - loss: 0.2054 - acc: 0.6474 - val_loss: 0.2244 - val_acc: 0.6469\n",
      "Epoch 63/100\n",
      "1s - loss: 0.2057 - acc: 0.6458 - val_loss: 0.2233 - val_acc: 0.6335\n",
      "Epoch 64/100\n",
      "1s - loss: 0.2061 - acc: 0.6448 - val_loss: 0.2213 - val_acc: 0.6437\n",
      "Epoch 65/100\n",
      "1s - loss: 0.2055 - acc: 0.6444 - val_loss: 0.2267 - val_acc: 0.6581\n",
      "Epoch 66/100\n",
      "1s - loss: 0.2053 - acc: 0.6433 - val_loss: 0.2240 - val_acc: 0.6233\n",
      "Epoch 67/100\n",
      "1s - loss: 0.2045 - acc: 0.6443 - val_loss: 0.2233 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "1s - loss: 0.2050 - acc: 0.6441 - val_loss: 0.2200 - val_acc: 0.6338\n",
      "Epoch 69/100\n",
      "1s - loss: 0.2046 - acc: 0.6435 - val_loss: 0.2198 - val_acc: 0.6431\n",
      "Epoch 70/100\n",
      "1s - loss: 0.2039 - acc: 0.6420 - val_loss: 0.2195 - val_acc: 0.6365\n",
      "Epoch 71/100\n",
      "1s - loss: 0.2038 - acc: 0.6425 - val_loss: 0.2214 - val_acc: 0.6285\n",
      "Epoch 72/100\n",
      "1s - loss: 0.2037 - acc: 0.6399 - val_loss: 0.2222 - val_acc: 0.6549\n",
      "Epoch 73/100\n",
      "1s - loss: 0.2028 - acc: 0.6434 - val_loss: 0.2207 - val_acc: 0.6355\n",
      "Epoch 74/100\n",
      "1s - loss: 0.2018 - acc: 0.6446 - val_loss: 0.2173 - val_acc: 0.6400\n",
      "Epoch 75/100\n",
      "1s - loss: 0.2015 - acc: 0.6402 - val_loss: 0.2243 - val_acc: 0.6141\n",
      "Epoch 76/100\n",
      "1s - loss: 0.2008 - acc: 0.6431 - val_loss: 0.2194 - val_acc: 0.6206\n",
      "Epoch 77/100\n",
      "1s - loss: 0.2002 - acc: 0.6419 - val_loss: 0.2164 - val_acc: 0.6467\n",
      "Epoch 78/100\n",
      "1s - loss: 0.1999 - acc: 0.6418 - val_loss: 0.2146 - val_acc: 0.6378\n",
      "Epoch 79/100\n",
      "1s - loss: 0.1998 - acc: 0.6438 - val_loss: 0.2147 - val_acc: 0.6417\n",
      "Epoch 80/100\n",
      "1s - loss: 0.1985 - acc: 0.6426 - val_loss: 0.2158 - val_acc: 0.6286\n",
      "Epoch 81/100\n",
      "1s - loss: 0.1987 - acc: 0.6421 - val_loss: 0.2147 - val_acc: 0.6341\n",
      "Epoch 82/100\n",
      "1s - loss: 0.1981 - acc: 0.6444 - val_loss: 0.2137 - val_acc: 0.6361\n",
      "Epoch 83/100\n",
      "1s - loss: 0.1974 - acc: 0.6427 - val_loss: 0.2117 - val_acc: 0.6345\n",
      "Epoch 84/100\n",
      "1s - loss: 0.1974 - acc: 0.6404 - val_loss: 0.2101 - val_acc: 0.6426\n",
      "Epoch 85/100\n",
      "1s - loss: 0.1972 - acc: 0.6400 - val_loss: 0.2099 - val_acc: 0.6404\n",
      "Epoch 86/100\n",
      "1s - loss: 0.1962 - acc: 0.6419 - val_loss: 0.2127 - val_acc: 0.6365\n",
      "Epoch 87/100\n",
      "1s - loss: 0.1968 - acc: 0.6428 - val_loss: 0.2117 - val_acc: 0.6450\n",
      "Epoch 88/100\n",
      "1s - loss: 0.1975 - acc: 0.6396 - val_loss: 0.2104 - val_acc: 0.6435\n",
      "Epoch 89/100\n",
      "1s - loss: 0.1957 - acc: 0.6415 - val_loss: 0.2101 - val_acc: 0.6353\n",
      "Epoch 90/100\n",
      "1s - loss: 0.1957 - acc: 0.6411 - val_loss: 0.2183 - val_acc: 0.6574\n",
      "Epoch 91/100\n",
      "1s - loss: 0.1947 - acc: 0.6432 - val_loss: 0.2100 - val_acc: 0.6442\n",
      "Epoch 92/100\n",
      "1s - loss: 0.1950 - acc: 0.6427 - val_loss: 0.2104 - val_acc: 0.6495\n",
      "Epoch 93/100\n",
      "1s - loss: 0.1942 - acc: 0.6437 - val_loss: 0.2183 - val_acc: 0.6647\n",
      "Epoch 94/100\n",
      "1s - loss: 0.1949 - acc: 0.6434 - val_loss: 0.2086 - val_acc: 0.6336\n",
      "Epoch 95/100\n",
      "1s - loss: 0.1933 - acc: 0.6423 - val_loss: 0.2083 - val_acc: 0.6421\n",
      "Epoch 96/100\n",
      "1s - loss: 0.1931 - acc: 0.6405 - val_loss: 0.2066 - val_acc: 0.6344\n",
      "Epoch 97/100\n",
      "1s - loss: 0.1928 - acc: 0.6412 - val_loss: 0.2113 - val_acc: 0.6156\n",
      "Epoch 98/100\n",
      "1s - loss: 0.1931 - acc: 0.6382 - val_loss: 0.2070 - val_acc: 0.6361\n",
      "Epoch 99/100\n",
      "1s - loss: 0.1929 - acc: 0.6370 - val_loss: 0.2056 - val_acc: 0.6353\n",
      "Epoch 100/100\n",
      "1s - loss: 0.1923 - acc: 0.6366 - val_loss: 0.2066 - val_acc: 0.6293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc3d9663c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100, verbose=2, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "RNN (SimpleRNN)              (None, 40, 4)             32        \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 2)             10        \n",
      "=================================================================\n",
      "Total params: 42.0\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 544/1000 [===============>..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20750950741767885, 0.63001249837875362]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the training, since we did use only a random subset of the data\n",
    "X, Y = data_matrix(X_train, Y_train, size=1000, num_steps=num_steps)\n",
    "model.evaluate(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.12037849, -1.25656247,  0.26881143, -0.14540911],\n",
       "        [ 0.1870168 ,  1.74302006,  0.01261289,  0.22220528],\n",
       "        [ 0.15347907, -2.05876875,  0.26264867,  0.12750585]], dtype=float32),\n",
       " array([[ 1.11681211, -0.46171117,  0.09308255, -0.01198333],\n",
       "        [-0.14963488,  0.12105057,  0.37936178,  0.27159336],\n",
       "        [-0.20190893, -0.06814966, -0.66770303,  1.72339237],\n",
       "        [ 1.5446769 , -0.48725992, -0.28641796,  1.07953584]], dtype=float32),\n",
       " array([-0.35291293, -0.24504972,  0.15703838,  0.08085969], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Using the TensorFlow API\n",
    "\n",
    "Alternatively one can use the TensorFlow-API for creating RNNs. In principle there are two TensorFlow methods. The first, kind of deprecated one, builds a graph from the unrolled network. This API has issues in performance, first of all the creation of the graph takes quite some time. Further, and this is a bit it is also slower during runtime. Therefore, the novel dynamic API should be prefered. If you want to use sequences of variable length see:  https://danijar.com/variable-sequence-lengths-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batch(Xs, Ys, batch_size = 32, num_steps = 50):\n",
    "    data_x = np.zeros([batch_size, num_steps], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, num_steps], dtype=np.int32)\n",
    "    for i in range(1,batch_size):\n",
    "        s = int(np.random.uniform(0, len(Xs) - num_steps))\n",
    "        data_x[i] = Xs[s : s + num_steps]\n",
    "        data_y[i] = Ys[s : s + num_steps]  \n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose:0' shape=(200, 40, 3) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "# RNN Inputs\n",
    "# One hot encoding.\n",
    "x_one_hot = tf.one_hot(x, num_classes_in)\n",
    "# We want the following dimensions [batch_size, Max_Length, num_classes_in]\n",
    "rnn_inputs = tf.transpose(x_one_hot, perm=(0,1,2))\n",
    "rnn_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Definition of the basic cell\n",
    "\n",
    "We have to define the elementary cell, which has a state of a given size. As above we use the basic RNN-Cell which is described in: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#cell = tf.nn.rnn_cell.BasicRNNCell(state_size) \n",
    "#cell = tf.nn.rnn_cell.BasicLSTMCell(state_size)\n",
    "# For tf1.0 the cells have been temporarily moved to a contib see: https://github.com/tensorflow/models/issues/919\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "init_state = cell.zero_state(batch_size, tf.float32)\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/transpose:0' shape=(200, 40, 4) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The output $o_{btk}$ tensor produces for each minibatch and timepoint a 4 (number of output states) dimensional vector indexed by $k$. For each timepoint and batch, we later want to compare this with the corresponding y-value with has the shape $y_{bt}$. In a first step we flatten the b and t dimension to a $200*40 = 8000$ dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Reshape_1:0' shape=(8000,) dtype=int32>,\n",
       " <tf.Tensor 'Reshape:0' shape=(8000, 4) dtype=float32>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape rnn_outputs and y so we can get the logits in a single matmul\n",
    "rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size])\n",
    "y_reshaped = tf.reshape(y, [-1])\n",
    "y_reshaped, rnn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'add:0' shape=(8000, 2) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_1:0' shape=(8000,) dtype=int32>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.variable_scope('softmax'):\n",
    "    V = tf.get_variable('V', [state_size, num_classes_out])\n",
    "    bv = tf.get_variable('bv', [num_classes_out], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "logits = tf.matmul(rnn_outputs, V) + bv\n",
    "logits, y_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#writer = tf.summary.FileWriter(\"tb_simple_rnn_tf1/dd\", tf.get_default_graph()) \n",
    "#writer.close()\n",
    "#!tensorboard --logdir=tb_simple_rnn_tf1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_reshaped, logits=logits))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-123b9d588c03>:7: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0 0.6798593997955322\n",
      "1 0.6539711952209473\n",
      "2 0.632749617099762\n",
      "3 0.6084426045417786\n",
      "4 0.5754246115684509\n",
      "5 0.5737156271934509\n",
      "6 0.5571834444999695\n",
      "7 0.522765040397644\n",
      "8 0.4930891692638397\n",
      "9 0.4334166347980499\n",
      "200 0.2222905765965347\n",
      "400 0.19082847386598586\n",
      "600 0.17908946476876736\n",
      "800 0.16760613091289997\n"
     ]
    }
   ],
   "source": [
    "Y = None\n",
    "X = None\n",
    "count = 0\n",
    "sum_tr_losses = 0\n",
    "sess = tf.Session()\n",
    "#with tf.Session() as sess:\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(1000):\n",
    "    X, Y = get_batch(X_train, Y_train, batch_size, num_steps)\n",
    "    tr_losses, _ = sess.run([total_loss, train_step], feed_dict={x:X, y:Y})\n",
    "    count += 1\n",
    "    sum_tr_losses += tr_losses\n",
    "    if (i < 10) or (i % 200 == 0):\n",
    "        print (\"{} {}\".format(i, sum_tr_losses / count))\n",
    "        count = 0\n",
    "        sum_tr_losses = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Test on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15980929"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = get_batch(X_train, Y_train, batch_size, num_steps)\n",
    "loss_train = sess.run(total_loss, feed_dict={x:X, y:Y})\n",
    "loss_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Getting the relevant weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Finding the relavant weights\n",
    "#ops = tf.get_default_graph().get_operations()\n",
    "#for i in ops:\n",
    "#   print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19089293  1.2079829   0.00908419 -0.91102362]\n",
      " [-1.07885635 -0.34288317  0.72712117  1.41788387]\n",
      " [-0.20597383 -0.19254826  0.7025221  -0.54543966]\n",
      " [ 1.03414631  0.67596245 -0.93610775  0.37894768]\n",
      " [-0.16711316  1.02640092 -0.89726377 -0.42267284]\n",
      " [ 0.20204762 -1.21461511  0.02345279  0.41776735]\n",
      " [-1.44821215  0.28976035 -1.87600672 -1.1563133 ]] [ 0.1347418   0.28151226  0.17300364 -0.32107899] [[-0.18110763  0.14144787]\n",
      " [ 2.24330831 -3.24425101]\n",
      " [-0.05769794  0.35383844]\n",
      " [ 0.0802527  -0.5142712 ]] [-0.35922614  0.35923496]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "W = graph.get_tensor_by_name('rnn/basic_rnn_cell/weights:0')\n",
    "b = graph.get_tensor_by_name('rnn/basic_rnn_cell/biases:0')\n",
    "W_,b_,V_,bv_ = sess.run([W,b,V,bv])\n",
    "print (W_,b_,V_,bv_)\n",
    "np.save('14_rnn_weights_tf1', [W_,b_,V_,bv_])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
